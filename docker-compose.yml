version: "3"
services:
  spark-master:
    build:
      context: "./"
      dockerfile: "Dockerfile.SparkLivy"
    container_name: spark-master
    ports:
    - "8998:8998"      
    - "8080:8080"
    - "7077:7077"
    environment:
    - "ENABLE_INIT_DAEMON=false"
  spark-worker:
    image: bde2020/spark-worker:latest
    container_name: spark-worker
    depends_on:
    - spark-master
    ports:
    - "8081:8081"
    environment:
    - "SPARK_MASTER=spark://spark-master:7077"
    - "ENABLE_INIT_DAEMON=false"
    deploy:
      replicas: 2

  # PostgreSQL database
  postgres:
    image: postgres:10-alpine
    container_name: "postgres"
    hostname: postgres
    restart: always
    env_file:
      - ./env/postgres-dev.env
    ports:
      - "5432:5432"
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
      - ./data/common:/data/common
    logging:
      # limit logs retained on host to 25MB
      driver: "json-file"
      options:
        max-size: "500k"
        max-file: "50"
    networks:
      - postgres-net

  rstudio:
    #image: rocker/rstudio:latest
    build:
      context: "./"
      dockerfile: "Dockerfile.Rstudio"
    container_name: "rstudio"
    depends_on:
      - postgres
    restart: always
    environment:
      - PASSWORD=mypassword
      # Not required as shiny is installed as part of the Docker image
      #- ADD=shiny
    # network_mode: "host"
    ports:
      - "8787:8787"
    volumes:
      - ./data:/home

  jupyterhub:
    depends_on:
      - postgres
    build:
      context: "./"
      dockerfile: "Dockerfile.Jupyterhub"
    ports:
      - "8000:8000"
    volumes:
      # Important: Mount the docker socket so that the Hub is able
      # to launch docker services on the manager node
      - /var/run/docker.sock:/var/run/docker.sock
      - ./jupyterhub_config.py:/srv/jupyterhub/jupyterhub_config.py
      - ./imgprep.py:/srv/jupyterhub/imgprep.py
      - ./data:/home
    env_file:
      - ./env/postgres-dev.env
    networks:
      - postgres-net

networks:
  postgres-net:
